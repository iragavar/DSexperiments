{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d096bc31-a270-43f5-b6ab-42749f5f06b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment initialized.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# STEP 1: Setup and Imports\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"âœ… Environment initialized.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3be790-f0b5-4ccc-bddf-7498351561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 3: Helper Functions\n",
    "# ==========================================================\n",
    "def normalize_status(s):\n",
    "    \"\"\"Normalize raw job status values.\"\"\"\n",
    "    s = str(s).strip().upper()\n",
    "    if s == \"COMPLETE\": return \"SUCCESS\"\n",
    "    if s == \"PENDING\": return \"PENDING\"\n",
    "    if s.startswith(\"ERROR - UPDATED\"): return \"SYSTEM_ABORT\"\n",
    "    if s == \"ERROR\": return \"ERROR\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "def find_prereq_candidates(job_row, df):\n",
    "    \"\"\"Resolve explicit design-time prerequisites (all_of / one_of).\"\"\"\n",
    "    job_type = job_row[\"Job_type\"]\n",
    "    start_time = pd.to_datetime(job_row[\"start_time\"])\n",
    "    billing_period = job_row[\"BillingPeriod\"]\n",
    "\n",
    "    deps = prereq_map.get(job_type, {\"all_of\": [], \"one_of\": []})\n",
    "    all_of, one_of = deps.get(\"all_of\", []), deps.get(\"one_of\", [])\n",
    "    satisfied = []\n",
    "\n",
    "    # --- all_of ---\n",
    "    for dep in all_of:\n",
    "        cand = df[\n",
    "            (df[\"Job_type\"] == dep)\n",
    "            & (df[\"BillingPeriod\"] == billing_period)\n",
    "            & (pd.to_datetime(df[\"end_time\"]) < start_time)\n",
    "        ]\n",
    "        if cand.empty:\n",
    "            return []  # missing required dependency\n",
    "        latest = cand.sort_values(\"end_time\").iloc[-1]\n",
    "        satisfied.append({\"dep\": dep, \"type\": \"all_of\", \"job\": latest})\n",
    "\n",
    "    # --- one_of ---\n",
    "    if one_of:\n",
    "        found = False\n",
    "        for dep in one_of:\n",
    "            cand = df[\n",
    "                (df[\"Job_type\"] == dep)\n",
    "                & (df[\"BillingPeriod\"] == billing_period)\n",
    "                & (pd.to_datetime(df[\"end_time\"]) < start_time)\n",
    "            ]\n",
    "            if not cand.empty:\n",
    "                latest = cand.sort_values(\"end_time\").iloc[-1]\n",
    "                satisfied.append({\"dep\": dep, \"type\": \"one_of\", \"job\": latest})\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            return []  # none satisfied\n",
    "    return satisfied\n",
    "\n",
    "def find_fallback_dependency(job_row, df):\n",
    "    \"\"\"If no design-time prereq, use most recent completed job in same period.\"\"\"\n",
    "    start_time = pd.to_datetime(job_row[\"start_time\"])\n",
    "    billing = job_row[\"BillingPeriod\"]\n",
    "    cand = df[\n",
    "        (pd.to_datetime(df[\"end_time\"]) < start_time)\n",
    "        & (df[\"BillingPeriod\"] == billing)\n",
    "    ].sort_values(\"end_time\")\n",
    "    if cand.empty:\n",
    "        return None, None\n",
    "    latest = cand.iloc[-1]\n",
    "    return latest[\"Job_type\"], latest[\"JobId\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f3fc8-56c2-4449-be97-9a86ecd61202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 2: Load Inputs\n",
    "# ==========================================================\n",
    "# ---- Job execution log (CSV) ----\n",
    "df = pd.read_csv(\"jobs_log.csv\")\n",
    "\n",
    "# ---- Prerequisite map (JSON) ----\n",
    "with open(\"job_prerequisites.json\", \"r\") as f:\n",
    "    prereq_map = {j[\"job_type\"]: j[\"dependencies\"] for j in json.load(f)}\n",
    "\n",
    "print(f\"âœ… Loaded {len(df)} job records and {len(prereq_map)} prerequisite definitions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ab04c1-6d90-4305-8d80-a7a29b0d068d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NodeView' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, n \u001b[38;5;129;01min\u001b[39;00m nodes_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 2\u001b[0m     G\u001b[38;5;241m.\u001b[39mnodes[n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJobLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_sim\u001b[39m\u001b[38;5;124m\"\u001b[39m: n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIsSimulated\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatusCat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     }\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NodeView' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for _, n in nodes_df.iterrows():\n",
    "    G.nodes[n[\"JobLabel\"]] = {\n",
    "        \"is_sim\": n[\"IsSimulated\"],\n",
    "        \"status\": n[\"StatusCat\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6afb5-69c5-4309-a2e5-2b6b264a6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 4: Build Nodes & Edges\n",
    "# ==========================================================\n",
    "edges, nodes = [], []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Parse job_configs JSON safely\n",
    "    try:\n",
    "        job_cfgs = json.loads(row[\"job_configs\"])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        job_cfgs = []\n",
    "    posting_flag = next((c.get(\"postingFlag\", True) for c in job_cfgs if \"postingFlag\" in c), True)\n",
    "    node_label = f\"{row['Job_type']}_Simulated\" if not posting_flag else row[\"Job_type\"]\n",
    "    status_cat = normalize_status(row[\"status\"])\n",
    "    is_sim = not posting_flag\n",
    "\n",
    "    nodes.append({\n",
    "        \"JobId\": row[\"JobId\"],\n",
    "        \"JobLabel\": node_label,\n",
    "        \"JobType\": row[\"Job_type\"],\n",
    "        \"IsSimulated\": is_sim,\n",
    "        \"StatusCat\": status_cat,\n",
    "        \"BillingPeriod\": row[\"BillingPeriod\"],\n",
    "        \"StartTime\": row[\"start_time\"],\n",
    "        \"EndTime\": row[\"end_time\"]\n",
    "    })\n",
    "\n",
    "    prereqs = find_prereq_candidates(row, df)\n",
    "    if prereqs:\n",
    "        for dep in prereqs:\n",
    "            edges.append({\n",
    "                \"SourceJob\": dep[\"dep\"],\n",
    "                \"TargetJob\": row[\"Job_type\"],\n",
    "                \"BillingPeriod\": row[\"BillingPeriod\"],\n",
    "                \"DependencyType\": dep[\"type\"],\n",
    "                \"DependencySourceId\": dep[\"job\"][\"JobId\"],\n",
    "                \"StatusCat\": status_cat\n",
    "            })\n",
    "    else:\n",
    "        src_type, src_id = find_fallback_dependency(row, df)\n",
    "        if src_type:\n",
    "            edges.append({\n",
    "                \"SourceJob\": src_type,\n",
    "                \"TargetJob\": row[\"Job_type\"],\n",
    "                \"BillingPeriod\": row[\"BillingPeriod\"],\n",
    "                \"DependencyType\": \"time_inferred\",\n",
    "                \"DependencySourceId\": src_id,\n",
    "                \"StatusCat\": status_cat\n",
    "            })\n",
    "\n",
    "print(f\"âœ… Extracted {len(nodes)} nodes and {len(edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028f4d6-1025-4c3a-a663-786d30980dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 5: Aggregate + Export\n",
    "# ==========================================================\n",
    "edges_df = pd.DataFrame(edges)\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "edges_agg = (\n",
    "    edges_df.groupby([\"SourceJob\",\"TargetJob\",\"BillingPeriod\",\"DependencyType\",\"StatusCat\"])\n",
    "    .size().reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "display(edges_agg.head(8))\n",
    "display(nodes_df.head(8))\n",
    "\n",
    "edges_agg.to_csv(\"edges_powerbi.csv\", index=False)\n",
    "nodes_df.to_csv(\"nodes_powerbi.csv\", index=False)\n",
    "print(\"ðŸ’¾ Exported edges_powerbi.csv and nodes_powerbi.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea4544-47d6-45b2-a77e-1ee6ddb4c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 6: Runtime Process Graph Visualization\n",
    "# ==========================================================\n",
    "G = nx.DiGraph()\n",
    "for _, r in edges_agg.iterrows():\n",
    "    color = (\n",
    "        \"blue\" if r[\"DependencyType\"] == \"all_of\"\n",
    "        else \"green\" if r[\"DependencyType\"] == \"one_of\"\n",
    "        else \"orange\"\n",
    "    )\n",
    "    if r[\"StatusCat\"] in [\"ERROR\",\"SYSTEM_ABORT\"]:\n",
    "        color = \"red\"\n",
    "    style = (\n",
    "        \"solid\" if r[\"DependencyType\"] == \"all_of\"\n",
    "        else \"dashed\" if r[\"DependencyType\"] == \"one_of\"\n",
    "        else \"dotted\"\n",
    "    )\n",
    "    G.add_edge(r[\"SourceJob\"], r[\"TargetJob\"], color=color, style=style, weight=r[\"Count\"])\n",
    "\n",
    "for _, n in nodes_df.iterrows():\n",
    "    G.nodes[n[\"JobLabel\"]] = {\n",
    "        \"is_sim\": n[\"IsSimulated\"],\n",
    "        \"status\": n[\"StatusCat\"]\n",
    "    }\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "pos = nx.spring_layout(G, k=0.6, seed=42)\n",
    "sim_nodes = [n for n,a in G.nodes(data=True) if a.get(\"is_sim\")]\n",
    "real_nodes = [n for n,a in G.nodes(data=True) if not a.get(\"is_sim\")]\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=sim_nodes,node_color=\"#6fa8dc\",\n",
    "                       node_shape=\"o\",label=\"Simulated\",node_size=800)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=real_nodes,node_color=\"#93c47d\",\n",
    "                       node_shape=\"s\",label=\"Actual\",node_size=800)\n",
    "\n",
    "for (u,v,d) in G.edges(data=True):\n",
    "    nx.draw_networkx_edges(G,pos,edgelist=[(u,v)],width=max(1,d[\"weight\"]/2),\n",
    "                           edge_color=d[\"color\"],style=d[\"style\"],\n",
    "                           arrows=True,arrowsize=15)\n",
    "\n",
    "failed_nodes = [n for n,a in G.nodes(data=True)\n",
    "                if a.get(\"status\") in [\"ERROR\",\"SYSTEM_ABORT\"]]\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=failed_nodes,node_color=\"none\",\n",
    "                       edgecolors=\"red\",linewidths=3,node_size=900)\n",
    "\n",
    "nx.draw_networkx_labels(G,pos,font_size=9,font_weight=\"bold\")\n",
    "plt.legend(scatterpoints=1,loc=\"upper left\",frameon=False)\n",
    "plt.title(\"Process Dependency Graph (Design + Inferred)\",fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
